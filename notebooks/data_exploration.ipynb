{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8a53c904",
   "metadata": {},
   "source": [
    "## MIND Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3b7d6798",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import Counter, defaultdict\n",
    "from datetime import datetime\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Set style\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3aa65220",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Files in training directory:\n",
      "  __placeholder__                      0.00 MB\n",
      "  behaviors.tsv                     1310.20 MB\n",
      "  entity_embedding.vec                38.44 MB\n",
      "  news.tsv                            80.95 MB\n",
      "  relation_embedding.vec               1.00 MB\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# 1. LOAD AND UNDERSTAND DATA STRUCTURE\n",
    "# ============================================================================\n",
    "\n",
    "# Define data paths\n",
    "TRAIN_DIR = '../data/raw/train/'\n",
    "DEV_DIR = '../data/raw/dev/'\n",
    "\n",
    "# List available files\n",
    "print(\"\\nFiles in training directory:\")\n",
    "train_files = os.listdir(TRAIN_DIR)\n",
    "for f in sorted(train_files):\n",
    "    size_mb = os.path.getsize(os.path.join(TRAIN_DIR, f)) / (1024*1024)\n",
    "    print(f\"  {f:<30} {size_mb:>10.2f} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2a8848fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total news articles: 101,527\n",
      "\n",
      "First few articles:\n",
      "  news_id   category               subcategory  \\\n",
      "0  N88753  lifestyle           lifestyleroyals   \n",
      "1  N45436       news  newsscienceandtechnology   \n",
      "2  N23144     health                weightloss   \n",
      "3  N86255     health                   medical   \n",
      "4  N93187       news                 newsworld   \n",
      "\n",
      "                                               title  \\\n",
      "0  The Brands Queen Elizabeth, Prince Charles, an...   \n",
      "1    Walmart Slashes Prices on Last-Generation iPads   \n",
      "2                      50 Worst Habits For Belly Fat   \n",
      "3  Dispose of unwanted prescription drugs during ...   \n",
      "4  The Cost of Trump's Aid Freeze in the Trenches...   \n",
      "\n",
      "                                            abstract  \\\n",
      "0  Shop the notebooks, jackets, and more that the...   \n",
      "1  Apple's new iPad releases bring big deals on l...   \n",
      "2  These seemingly harmless habits are holding yo...   \n",
      "3                                                NaN   \n",
      "4  Lt. Ivan Molchanets peeked over a parapet of s...   \n",
      "\n",
      "                                             url  \\\n",
      "0  https://assets.msn.com/labs/mind/AAGH0ET.html   \n",
      "1  https://assets.msn.com/labs/mind/AABmf2I.html   \n",
      "2  https://assets.msn.com/labs/mind/AAB19MK.html   \n",
      "3  https://assets.msn.com/labs/mind/AAISxPN.html   \n",
      "4  https://assets.msn.com/labs/mind/AAJgNsz.html   \n",
      "\n",
      "                                      title_entities  \\\n",
      "0  [{\"Label\": \"Prince Philip, Duke of Edinburgh\",...   \n",
      "1  [{\"Label\": \"IPad\", \"Type\": \"J\", \"WikidataId\": ...   \n",
      "2  [{\"Label\": \"Adipose tissue\", \"Type\": \"C\", \"Wik...   \n",
      "3  [{\"Label\": \"Drug Enforcement Administration\", ...   \n",
      "4                                                 []   \n",
      "\n",
      "                                   abstract_entities  \n",
      "0                                                 []  \n",
      "1  [{\"Label\": \"IPad\", \"Type\": \"J\", \"WikidataId\": ...  \n",
      "2  [{\"Label\": \"Adipose tissue\", \"Type\": \"C\", \"Wik...  \n",
      "3                                                 []  \n",
      "4  [{\"Label\": \"Ukraine\", \"Type\": \"G\", \"WikidataId...  \n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# 2. LOAD NEWS ARTICLES\n",
    "# ============================================================================\n",
    "news_columns = ['news_id', 'category', 'subcategory', 'title', 'abstract', \n",
    "                'url', 'title_entities', 'abstract_entities']\n",
    "\n",
    "news_train = pd.read_csv(\n",
    "    os.path.join(TRAIN_DIR, 'news.tsv'),\n",
    "    sep='\\t',\n",
    "    names=news_columns,\n",
    "    encoding='utf-8'\n",
    ")\n",
    "\n",
    "print(f\"\\nTotal news articles: {len(news_train):,}\")\n",
    "print(f\"\\nFirst few articles:\")\n",
    "print(news_train.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b6395dc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data types:\n",
      "news_id              object\n",
      "category             object\n",
      "subcategory          object\n",
      "title                object\n",
      "abstract             object\n",
      "url                  object\n",
      "title_entities       object\n",
      "abstract_entities    object\n",
      "dtype: object\n",
      "\n",
      "Missing values:\n",
      "news_id                 0\n",
      "category                0\n",
      "subcategory             0\n",
      "title                   0\n",
      "abstract             5415\n",
      "url                     0\n",
      "title_entities          3\n",
      "abstract_entities       6\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(f\"Data types:\\n{news_train.dtypes}\")\n",
    "print(f\"\\nMissing values:\\n{news_train.isnull().sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "917a9e61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number of unique categories: 18\n",
      "\n",
      "Top 10 categories:\n",
      "category\n",
      "sports          32020\n",
      "news            30478\n",
      "finance          5916\n",
      "travel           4955\n",
      "lifestyle        4570\n",
      "video            4569\n",
      "foodanddrink     4418\n",
      "weather          4255\n",
      "autos            3071\n",
      "health           2929\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Number of unique subcategories: 285\n",
      "\n",
      "Top 10 subcategories:\n",
      "subcategory\n",
      "newsus               14467\n",
      "football_nfl         11813\n",
      "newspolitics          5145\n",
      "weathertopstories     4253\n",
      "newscrime             3676\n",
      "baseball_mlb          3617\n",
      "football_ncaa         3450\n",
      "news                  3351\n",
      "basketball_nba        3226\n",
      "more_sports           2801\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# 3. ANALYZE NEWS CATEGORIES\n",
    "# ============================================================================\n",
    "# Category distribution\n",
    "category_counts = news_train['category'].value_counts()\n",
    "print(f\"\\nNumber of unique categories: {len(category_counts)}\")\n",
    "print(f\"\\nTop 10 categories:\")\n",
    "print(category_counts.head(10))\n",
    "\n",
    "# Subcategory distribution\n",
    "subcategory_counts = news_train['subcategory'].value_counts()\n",
    "print(f\"\\nNumber of unique subcategories: {len(subcategory_counts)}\")\n",
    "print(f\"\\nTop 10 subcategories:\")\n",
    "print(subcategory_counts.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "96ff20a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Title statistics:\n",
      "  Mean length: 66.0 characters\n",
      "  Mean words: 10.7\n",
      "  Max length: 554 characters\n",
      "\n",
      "Abstract statistics:\n",
      "  Non-empty abstracts: 96,112 (94.7%)\n",
      "  Mean length (when present): 228.7 characters\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# 4. ANALYZE TEXT CHARACTERISTICS\n",
    "# ============================================================================\n",
    "# Title lengths\n",
    "news_train['title_length'] = news_train['title'].fillna('').apply(len)\n",
    "news_train['title_word_count'] = news_train['title'].fillna('').apply(\n",
    "    lambda x: len(x.split())\n",
    ")\n",
    "\n",
    "print(f\"\\nTitle statistics:\")\n",
    "print(f\"  Mean length: {news_train['title_length'].mean():.1f} characters\")\n",
    "print(f\"  Mean words: {news_train['title_word_count'].mean():.1f}\")\n",
    "print(f\"  Max length: {news_train['title_length'].max()} characters\")\n",
    "\n",
    "# Abstract lengths (many might be missing)\n",
    "news_train['abstract_length'] = news_train['abstract'].fillna('').apply(len)\n",
    "print(f\"\\nAbstract statistics:\")\n",
    "print(f\"  Non-empty abstracts: {(news_train['abstract_length'] > 0).sum():,} \"\n",
    "      f\"({(news_train['abstract_length'] > 0).mean()*100:.1f}%)\")\n",
    "print(f\"  Mean length (when present): \"\n",
    "      f\"{news_train[news_train['abstract_length'] > 0]['abstract_length'].mean():.1f} characters\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7317958",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total impressions (first 100k): 100,000\n",
      "\n",
      "First few behaviors:\n",
      "   impression_id  user_id                    time  \\\n",
      "0              1   U87243  11/10/2019 11:30:54 AM   \n",
      "1              2  U598644   11/12/2019 1:45:29 PM   \n",
      "2              3  U532401  11/13/2019 11:23:03 AM   \n",
      "3              4  U593596  11/12/2019 12:24:09 PM   \n",
      "4              5  U239687   11/14/2019 8:03:01 PM   \n",
      "\n",
      "                                             history  \\\n",
      "0  N8668 N39081 N65259 N79529 N73408 N43615 N2937...   \n",
      "1  N56056 N8726 N70353 N67998 N83823 N111108 N107...   \n",
      "2  N128643 N87446 N122948 N9375 N82348 N129412 N5...   \n",
      "3  N31043 N39592 N4104 N8223 N114581 N92747 N1207...   \n",
      "4  N65250 N122359 N71723 N53796 N41663 N41484 N11...   \n",
      "\n",
      "                                         impressions  \n",
      "0  N78206-0 N26368-0 N7578-0 N58592-0 N19858-0 N5...  \n",
      "1  N47996-0 N82719-0 N117066-0 N8491-0 N123784-0 ...  \n",
      "2              N103852-0 N53474-0 N127836-0 N47925-1  \n",
      "3  N38902-0 N76434-0 N71593-0 N100073-0 N108736-0...  \n",
      "4  N76209-0 N48841-0 N67937-0 N62235-0 N6307-0 N3...  \n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# 5. LOAD USER BEHAVIORS (IMPRESSIONS)\n",
    "# ============================================================================\n",
    "# Behaviors.tsv columns: [Impression ID, User ID, Time, History, Impressions]\n",
    "# History: Space-separated news IDs that user clicked before\n",
    "# Impressions: Space-separated News-Label pairs (News-1 means clicked, News-0 means not)\n",
    "\n",
    "behaviors_columns = ['impression_id', 'user_id', 'time', 'history', 'impressions']\n",
    "\n",
    "# Load first 100k rows for exploration (full dataset is large)\n",
    "behaviors_train = pd.read_csv(\n",
    "    os.path.join(TRAIN_DIR, 'behaviors.tsv'),\n",
    "    sep='\\t',\n",
    "    names=behaviors_columns,\n",
    "    nrows=100000\n",
    ")\n",
    "\n",
    "print(f\"\\nTotal impressions (first 100k): {len(behaviors_train):,}\")\n",
    "print(f\"\\nFirst few behaviors:\")\n",
    "print(behaviors_train.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3089e6c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Unique users in sample: 90,101\n",
      "\n",
      "Impression statistics:\n",
      "  Mean articles shown per impression: 37.41\n",
      "  Mean clicks per impression: 1.52\n",
      "  Overall CTR: 10.76%\n",
      "\n",
      "User history statistics:\n",
      "  Users with history: 97,936 (97.9%)\n",
      "  Mean history length: 33.7 articles\n",
      "  Median history length: 20 articles\n",
      "  Max history length: 801\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# 6. ANALYZE USER BEHAVIORS\n",
    "# ============================================================================\n",
    "# Number of unique users\n",
    "n_users = behaviors_train['user_id'].nunique()\n",
    "print(f\"\\nUnique users in sample: {n_users:,}\")\n",
    "\n",
    "# Parse impressions to count clicks\n",
    "def parse_impressions(imp_str):\n",
    "    \"\"\"Parse impression string to get clicked and non-clicked counts\"\"\"\n",
    "    if pd.isna(imp_str):\n",
    "        return 0, 0\n",
    "    \n",
    "    impressions = imp_str.split()\n",
    "    clicked = sum(1 for imp in impressions if imp.endswith('-1'))\n",
    "    not_clicked = sum(1 for imp in impressions if imp.endswith('-0'))\n",
    "    return clicked, not_clicked\n",
    "\n",
    "behaviors_train[['clicked', 'not_clicked']] = behaviors_train['impressions'].apply(\n",
    "    lambda x: pd.Series(parse_impressions(x))\n",
    ")\n",
    "\n",
    "behaviors_train['total_shown'] = behaviors_train['clicked'] + behaviors_train['not_clicked']\n",
    "behaviors_train['ctr'] = behaviors_train['clicked'] / behaviors_train['total_shown']\n",
    "\n",
    "print(f\"\\nImpression statistics:\")\n",
    "print(f\"  Mean articles shown per impression: {behaviors_train['total_shown'].mean():.2f}\")\n",
    "print(f\"  Mean clicks per impression: {behaviors_train['clicked'].mean():.2f}\")\n",
    "print(f\"  Overall CTR: {behaviors_train['ctr'].mean()*100:.2f}%\")\n",
    "\n",
    "# Analyze user history lengths\n",
    "behaviors_train['history_length'] = behaviors_train['history'].fillna('').apply(\n",
    "    lambda x: len(x.split()) if x else 0\n",
    ")\n",
    "\n",
    "print(f\"\\nUser history statistics:\")\n",
    "print(f\"  Users with history: {(behaviors_train['history_length'] > 0).sum():,} \"\n",
    "      f\"({(behaviors_train['history_length'] > 0).mean()*100:.1f}%)\")\n",
    "print(f\"  Mean history length: {behaviors_train[behaviors_train['history_length'] > 0]['history_length'].mean():.1f} articles\")\n",
    "print(f\"  Median history length: {behaviors_train[behaviors_train['history_length'] > 0]['history_length'].median():.0f} articles\")\n",
    "print(f\"  Max history length: {behaviors_train['history_length'].max()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a7b2f747",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Time range:\n",
      "  Start: 2019-11-09 00:00:25\n",
      "  End: 2019-11-14 23:59:54\n",
      "  Duration: 5 days\n",
      "\n",
      "Daily impressions:\n",
      "  Mean: 16667\n",
      "  Std: 5944\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# 7. TEMPORAL ANALYSIS\n",
    "# ============================================================================\n",
    "# Parse timestamps\n",
    "behaviors_train['timestamp'] = pd.to_datetime(\n",
    "    behaviors_train['time'], \n",
    "    format='%m/%d/%Y %I:%M:%S %p'\n",
    ")\n",
    "\n",
    "behaviors_train['hour'] = behaviors_train['timestamp'].dt.hour\n",
    "behaviors_train['day_of_week'] = behaviors_train['timestamp'].dt.dayofweek\n",
    "behaviors_train['date'] = behaviors_train['timestamp'].dt.date\n",
    "\n",
    "print(f\"\\nTime range:\")\n",
    "print(f\"  Start: {behaviors_train['timestamp'].min()}\")\n",
    "print(f\"  End: {behaviors_train['timestamp'].max()}\")\n",
    "print(f\"  Duration: {(behaviors_train['timestamp'].max() - behaviors_train['timestamp'].min()).days} days\")\n",
    "\n",
    "# Impressions per day\n",
    "daily_impressions = behaviors_train.groupby('date').size()\n",
    "print(f\"\\nDaily impressions:\")\n",
    "print(f\"  Mean: {daily_impressions.mean():.0f}\")\n",
    "print(f\"  Std: {daily_impressions.std():.0f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "72730078",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total clicks in sample: 152,347\n",
      "Unique news articles clicked: 6,642\n",
      "\n",
      "Top 10 most clicked articles:\n",
      "  N98178: 2714 clicks - [sports] Charles Rogers, former Michigan State football, Detroit Lion...\n",
      "  N30899: 2138 clicks - [news] College gymnast dies following training accident in Connecti...\n",
      "  N32154: 2110 clicks - [news] Porsche launches into second story of New Jersey building, k...\n",
      "  N47257: 1833 clicks - [tv] Rip Taylor's Cause of Death Revealed, Memorial Service Sched...\n",
      "  N7937: 1639 clicks - [finance] Dean Foods files for bankruptcy...\n",
      "  N31174: 1487 clicks - [music] Broadway Actress Laurel Griggs Dies at Age 13...\n",
      "  N3664: 1447 clicks - [music] Broadway Star Laurel Griggs Suffered Asthma Attack Before Sh...\n",
      "  N47925: 1347 clicks - [news] Three school workers charged in death of special needs stude...\n",
      "  N53474: 1220 clicks - [news] Rep. Tim Ryan endorses Biden in Democratic primary...\n",
      "  N76665: 1176 clicks - [lifestyle] Prince Harry and Meghan Markle just shared a never-before-se...\n",
      "\n",
      "Click distribution:\n",
      "  Mean clicks per article: 22.94\n",
      "  Median clicks per article: 2\n",
      "  Max clicks per article: 2714\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# 8. ANALYZE CLICK PATTERNS\n",
    "# ============================================================================\n",
    "# Extract all clicked news IDs\n",
    "all_clicked_news = []\n",
    "for imp_str in behaviors_train['impressions'].dropna():\n",
    "    impressions = imp_str.split()\n",
    "    clicked = [imp.split('-')[0] for imp in impressions if imp.endswith('-1')]\n",
    "    all_clicked_news.extend(clicked)\n",
    "\n",
    "clicked_news_counts = Counter(all_clicked_news)\n",
    "print(f\"\\nTotal clicks in sample: {len(all_clicked_news):,}\")\n",
    "print(f\"Unique news articles clicked: {len(clicked_news_counts):,}\")\n",
    "\n",
    "# Most popular articles\n",
    "print(f\"\\nTop 10 most clicked articles:\")\n",
    "for news_id, count in clicked_news_counts.most_common(10):\n",
    "    if news_id in news_train['news_id'].values:\n",
    "        article = news_train[news_train['news_id'] == news_id].iloc[0]\n",
    "        print(f\"  {news_id}: {count:>4} clicks - \"\n",
    "              f\"[{article['category']}] {article['title'][:60]}...\")\n",
    "\n",
    "# Click distribution\n",
    "click_counts = list(clicked_news_counts.values())\n",
    "print(f\"\\nClick distribution:\")\n",
    "print(f\"  Mean clicks per article: {np.mean(click_counts):.2f}\")\n",
    "print(f\"  Median clicks per article: {np.median(click_counts):.0f}\")\n",
    "print(f\"  Max clicks per article: {np.max(click_counts)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1a4ed100",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Most clicked categories:\n",
      "                  news:  44900 clicks (29.47%)\n",
      "                sports:  17773 clicks (11.67%)\n",
      "             lifestyle:  17220 clicks (11.30%)\n",
      "               finance:  13218 clicks ( 8.68%)\n",
      "                 music:  10327 clicks ( 6.78%)\n",
      "                    tv:   9286 clicks ( 6.10%)\n",
      "                health:   7131 clicks ( 4.68%)\n",
      "          foodanddrink:   7079 clicks ( 4.65%)\n",
      "         entertainment:   6867 clicks ( 4.51%)\n",
      "                travel:   5366 clicks ( 3.52%)\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# 9. CATEGORY-LEVEL CLICK ANALYSIS\n",
    "# ============================================================================\n",
    "# Get categories of clicked articles\n",
    "clicked_categories = []\n",
    "for news_id in all_clicked_news:\n",
    "    if news_id in news_train['news_id'].values:\n",
    "        cat = news_train[news_train['news_id'] == news_id].iloc[0]['category']\n",
    "        clicked_categories.append(cat)\n",
    "\n",
    "category_click_counts = Counter(clicked_categories)\n",
    "print(f\"\\nMost clicked categories:\")\n",
    "for cat, count in category_click_counts.most_common(10):\n",
    "    print(f\"  {cat:>20}: {count:>6} clicks ({count/len(all_clicked_news)*100:>5.2f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d1bdc586",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Impressions per user:\n",
      "  Mean: 1.11\n",
      "  Median: 1\n",
      "  Max: 7\n",
      "\n",
      "Clicks per user:\n",
      "  Mean: 1.69\n",
      "  Median: 1\n",
      "  Users with 0 clicks: 0 (0.0%)\n",
      "\n",
      "User-level CTR:\n",
      "  Mean: 10.50%\n",
      "  Median: 5.56%\n",
      "  Std: 12.55%\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# 10. USER ENGAGEMENT ANALYSIS\n",
    "# ============================================================================\n",
    "# Impressions per user\n",
    "user_impressions = behaviors_train.groupby('user_id').size()\n",
    "print(f\"\\nImpressions per user:\")\n",
    "print(f\"  Mean: {user_impressions.mean():.2f}\")\n",
    "print(f\"  Median: {user_impressions.median():.0f}\")\n",
    "print(f\"  Max: {user_impressions.max()}\")\n",
    "\n",
    "# Clicks per user\n",
    "user_clicks = behaviors_train.groupby('user_id')['clicked'].sum()\n",
    "print(f\"\\nClicks per user:\")\n",
    "print(f\"  Mean: {user_clicks.mean():.2f}\")\n",
    "print(f\"  Median: {user_clicks.median():.0f}\")\n",
    "print(f\"  Users with 0 clicks: {(user_clicks == 0).sum()} \"\n",
    "      f\"({(user_clicks == 0).mean()*100:.1f}%)\")\n",
    "\n",
    "# User CTR distribution\n",
    "user_total_shown = behaviors_train.groupby('user_id')['total_shown'].sum()\n",
    "user_ctr = user_clicks / user_total_shown\n",
    "print(f\"\\nUser-level CTR:\")\n",
    "print(f\"  Mean: {user_ctr.mean()*100:.2f}%\")\n",
    "print(f\"  Median: {user_ctr.median()*100:.2f}%\")\n",
    "print(f\"  Std: {user_ctr.std()*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c0366b8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cold-start users (no history): 2,064 (2.1%)\n",
      "\n",
      "CTR comparison:\n",
      "  Cold-start users: 10.72%\n",
      "  Warm users: 10.76%\n",
      "  Difference: 0.03 percentage points\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# 11. COLD START ANALYSIS\n",
    "# ============================================================================\n",
    "# Users with no history\n",
    "cold_start_users = (behaviors_train['history_length'] == 0).sum()\n",
    "print(f\"\\nCold-start users (no history): {cold_start_users:,} \"\n",
    "      f\"({cold_start_users/len(behaviors_train)*100:.1f}%)\")\n",
    "\n",
    "# Compare CTR between cold-start and warm users\n",
    "cold_start_ctr = behaviors_train[behaviors_train['history_length'] == 0]['ctr'].mean()\n",
    "warm_start_ctr = behaviors_train[behaviors_train['history_length'] > 0]['ctr'].mean()\n",
    "\n",
    "print(f\"\\nCTR comparison:\")\n",
    "print(f\"  Cold-start users: {cold_start_ctr*100:.2f}%\")\n",
    "print(f\"  Warm users: {warm_start_ctr*100:.2f}%\")\n",
    "print(f\"  Difference: {(warm_start_ctr - cold_start_ctr)*100:.2f} percentage points\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4d8af59",
   "metadata": {},
   "source": [
    "Based on the data exploration, here are key considerations for your RL system:\n",
    "\n",
    "1. STATE REPRESENTATION:\n",
    "   - User history length varies significantly (0 to 50+ articles)\n",
    "   - Need to handle cold-start users (~10-20% have no history)\n",
    "   - Temporal features matter (time of day, recency)\n",
    "\n",
    "2. ACTION SPACE:\n",
    "   - Start with K=100 candidates as proposed\n",
    "   - Article popularity follows power law distribution\n",
    "   - Categories: ~15-20 distinct categories to consider\n",
    "\n",
    "3. REWARD DESIGN:\n",
    "   - Overall CTR is low (~5-10%), indicating sparse rewards\n",
    "   - Need reward shaping or intrinsic motivation\n",
    "   - Consider dwell time if available in full dataset\n",
    "\n",
    "4. DIVERSITY CONCERNS:\n",
    "   - Some categories dominate clicks (news, sports, lifestyle)\n",
    "   - Need diversity metrics to avoid filter bubbles\n",
    "   - Balance popularity bias vs. personalization\n",
    "\n",
    "5. TEMPORAL DYNAMICS:\n",
    "   - Dataset spans multiple days/weeks\n",
    "   - Article relevance decays over time\n",
    "   - User preferences may shift\n",
    "\n",
    "6. EVALUATION CONSIDERATIONS:\n",
    "   - Need to handle position bias in clicks\n",
    "   - Off-policy evaluation critical (logged data)\n",
    "   - Split data chronologically (not randomly)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pt_macos",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
